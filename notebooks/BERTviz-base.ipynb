{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f99d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pprint\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\" # Set GPU Index to use\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import copy\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch.nn import CrosnsEntropyLoss, MSELoss\n",
    "from tqdm import tqdm\n",
    "from transformer import BertForSequenceClassification,WEIGHTS_NAME, CONFIG_NAME\n",
    "from transformer.modeling_quant import BertForSequenceClassification as QuantBertForSequenceClassification\n",
    "from transformer import BertTokenizer\n",
    "from transformer import BertAdam\n",
    "from transformer import BertConfig\n",
    "from transformer import QuantizeLinear, QuantizeAct, BertSelfAttention, FP_BertSelfAttention, ClipLinear\n",
    "from utils_glue import *\n",
    "from bertviz import model_view\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0 \n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def cv_initialize(model, loader, ratio, device):\n",
    "    \n",
    "    def initialize_hook(module, input, output):\n",
    "        if isinstance(module, (QuantizeLinear, QuantizeAct, ClipLinear)):\n",
    "            \"\"\"KDLSQ-BERT ACT Quant init Method\n",
    "            Ref: https://arxiv.org/abs/2101.05938\n",
    "            \"\"\"\n",
    "            if not isinstance(input, torch.Tensor):\n",
    "                input = input[0]\n",
    "        \n",
    "            n = torch.numel(input)\n",
    "            input_sorted, index = torch.sort(input.reshape(-1), descending=False)\n",
    "            \n",
    "            index_min = torch.round(ratio * n / 2)\n",
    "            index_max = n - index_min\n",
    "            \n",
    "            s_init = (input_sorted[int(index_min)].to(device), input_sorted[int(index_max)].to(device))\n",
    "            \n",
    "            # MATPLOT\n",
    "            \n",
    "            fig, [ax1, ax2, ax3] = plt.subplots(1,3, figsize=(16, 4))            \n",
    "            \n",
    "            sns.histplot(data=input.reshape(-1).detach().cpu().numpy(), kde = True, bins=100, ax=ax1)\n",
    "            sns.rugplot(data=input.reshape(-1).detach().cpu().numpy(), ax=ax1)\n",
    "            sns.histplot(data=module.weight.reshape(-1).detach().cpu().numpy(), kde = True, bins=100, ax=ax2)\n",
    "            sns.rugplot(data=module.weight.reshape(-1).detach().cpu().numpy(), ax=ax2)\n",
    "            sns.histplot(data=output.reshape(-1).detach().cpu().numpy(), kde = True, bins=100, ax=ax3)\n",
    "            sns.rugplot(data=output.reshape(-1).detach().cpu().numpy(), ax=ax3)\n",
    "            # fig, [ax1, ax2] = plt.subplots(1,2, figsize=(12, 4))            \n",
    "            \n",
    "            # sns.distplot(input.reshape(-1).detach().cpu().numpy() , hist = True, rug = True, kde = True, bins=100, norm_hist=False, kde_kws=dict(linewidth=0.5), rug_kws=dict(linewidth=0.5), ax=ax1)\n",
    "            # sns.distplot(output.reshape(-1).detach().cpu().numpy() , hist = True, rug = True, kde = True, bins=100, norm_hist=False, kde_kws=dict(linewidth=0.5), rug_kws=dict(linewidth=0.5), ax=ax2)\n",
    "            # # plt.axvline(x=s_init[0].detach().cpu().numpy(), color='r', linestyle='--')\n",
    "            # # plt.axvline(x=s_init[1].detach().cpu().numpy(), color='r', linestyle='--')\n",
    "\n",
    "            ax1.set_xlabel(\"Input Activation\")\n",
    "            # ax2.set_xlabel(\"Output Activation\")\n",
    "            ax2.set_xlabel(\"Module Weight\")\n",
    "            ax3.set_xlabel(\"Output Activation\")\n",
    "            \n",
    "            ax1.set_ylabel(\"Density\")\n",
    "            ax2.set_ylabel(\"Density\")\n",
    "            ax3.set_ylabel(\"Density\")\n",
    "\n",
    "            ax1.set_title(f\"{module.name} Input ACT histogram\")\n",
    "            # ax2.set_title(f\"{module.name} Output ACT histogram\")\n",
    "            ax2.set_title(f\"{module.name} Weight histogram\")\n",
    "            ax3.set_title(f\"{module.name} Output ACT histogram\")\n",
    "            # plt.savefig(f\"plt_storage/hook_inputs/sst-2-fp/{module.name}.png\")\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "            # module.clip_initialize(s_init)\n",
    "            # logger.info(f\"{module} : min {s_init[0].item()} max {s_init[1].item()}\") \n",
    "\n",
    "    \n",
    "    hooks = []\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        hook = module.register_forward_hook(initialize_hook)\n",
    "        hooks.append(hook)\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = tuple(t.to(\"cuda\") for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch        \n",
    "        with torch.no_grad():\n",
    "            student_logits, student_atts, student_reps, student_probs, student_values = model(input_ids, segment_ids, input_mask, teacher_probs=None)\n",
    "        break\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    index = 0\n",
    "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        while True:\n",
    "            token = reader.readline()\n",
    "            if not token:\n",
    "                break\n",
    "            token = token.strip()\n",
    "            #vocab[token] = index\n",
    "            vocab[index] = token\n",
    "            index += 1\n",
    "    return vocab\n",
    "\n",
    "def attention_pattern(model, loader, device):\n",
    "    \n",
    "    def initialize_hook(module, input, output):\n",
    "        if isinstance(module, BertSelfAttention):\n",
    "            \n",
    "            attn_mask = input[1]\n",
    "            attention_output = output[-2][\"attn\"]\n",
    "            \n",
    "            seq_length = (attn_mask == 0).sum()\n",
    "            \n",
    "            print(attention_output[0,:,:seq_length,seq_length-1].mean().item())\n",
    "            \n",
    "\n",
    "    hooks = []\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        hook = module.register_forward_hook(initialize_hook)\n",
    "        hooks.append(hook)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = tuple(t.to(\"cuda\") for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch        \n",
    "        with torch.no_grad():\n",
    "            student_logits, student_atts, student_reps, student_probs, student_values = model(input_ids, segment_ids, input_mask)\n",
    "        break\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "        \n",
    "def get_tensor_data(output_mode, features):\n",
    "    if output_mode == \"classification\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
    "\n",
    "\n",
    "    all_seq_lengths = torch.tensor([f.seq_length for f in features], dtype=torch.long)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    tensor_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label_ids, all_seq_lengths)\n",
    "    return tensor_data, all_label_ids\n",
    "\n",
    "def do_logging(run, student_model, teacher_model, test_dataloader, device, global_step, args, vocab):\n",
    "    \n",
    "    if args.bert == \"large\":\n",
    "        layer_num = 24\n",
    "        head_num = 16\n",
    "    else:\n",
    "        layer_num = 12\n",
    "        head_num = 12\n",
    "        \n",
    "    nb_steps = 0\n",
    "    \n",
    "    kl_div_sum = [0 for i in range(layer_num)]\n",
    "    st_sep_avg_sum = [0 for i in range(layer_num)]; st_cls_avg_sum = [0 for i in range(layer_num)]; tc_sep_avg_sum = [0 for i in range(layer_num)]; tc_cls_avg_sum = [0 for i in range(layer_num)]\n",
    "    cover_sum = [0 for i in range(layer_num)]\n",
    "    cover_teacher_sum = [0 for i in range(layer_num)]\n",
    "    \n",
    "    batch_num = 0\n",
    "    \n",
    "    for batch_ in tqdm(test_dataloader, desc=\"Logging Test\", mininterval=0.01, ascii=True, leave=False):\n",
    "        batch_ = tuple(t.to(device) for t in batch_)\n",
    "        \n",
    "        if batch_num >= 1: # Visualize Attention Map only First Batch \n",
    "            args.log_map = False\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, segment_ids, label_id, seq_length = batch_\n",
    "\n",
    "            teacher_logits, teacher_atts, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids, segment_ids, input_mask)\n",
    "            student_logits, student_atts, student_reps, student_probs, student_values = student_model(input_ids, segment_ids, input_mask, teacher_probs=teacher_probs)\n",
    "            \n",
    "            # Layer\n",
    "            for i, (student_prob, teacher_prob) in enumerate(zip(student_probs, teacher_probs)): \n",
    "\n",
    "                # Head\n",
    "                for head in range(head_num):\n",
    "                    \n",
    "                    if args.log_map:\n",
    "                        \n",
    "                        word_list = []\n",
    "                        \n",
    "                        for word in range(seq_length):\n",
    "                            word_list.append(vocab[input_ids[0][word].item()])\n",
    "                        \n",
    "                        student_prob_map = student_prob[0][head][:seq_length,:seq_length].clone().detach().cpu().numpy()\n",
    "                        teacher_prob_map = teacher_prob[0][head][:seq_length,:seq_length].clone().detach().cpu().numpy()\n",
    "                        \n",
    "                        fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(16,8))\n",
    "                        ax1.set_title(f\"{i}th Layer {head}th Head Teacher\")\n",
    "                        heatmap = ax1.pcolor(teacher_prob_map, cmap=plt.cm.Blues)\n",
    "    \n",
    "                        ax1.set_xticks(numpy.arange(teacher_prob_map.shape[1]) + 0.5, minor=False)\n",
    "                        ax1.set_yticks(numpy.arange(teacher_prob_map.shape[0]) + 0.5, minor=False)\n",
    "                        \n",
    "                        ax1.set_xlim(0, int(teacher_prob_map.shape[1]))\n",
    "                        ax1.set_ylim(0, int(teacher_prob_map.shape[0]))\n",
    "\n",
    "                        ax1.invert_yaxis()\n",
    "                        ax1.xaxis.tick_top()\n",
    "\n",
    "                        ax1.set_xticklabels(word_list, minor=False)\n",
    "                        ax1.set_yticklabels(word_list, minor=False)\n",
    "\n",
    "                        plt.xticks(rotation=45)\n",
    "                        \n",
    "                        ax2.set_title(f\"{i}th Layer {head}th Head Student\")\n",
    "                        heatmap = ax2.pcolor(student_prob_map, cmap=plt.cm.Blues)\n",
    "\n",
    "                        ax2.set_xticks(numpy.arange(student_prob_map.shape[1]) + 0.5, minor=False)\n",
    "                        ax2.set_yticks(numpy.arange(student_prob_map.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "                        ax2.set_xlim(0, int(student_prob_map.shape[1]))\n",
    "                        ax2.set_ylim(0, int(student_prob_map.shape[0]))\n",
    "\n",
    "                        ax2.invert_yaxis()\n",
    "                        ax2.xaxis.tick_top()\n",
    "\n",
    "                        ax2.set_xticklabels(word_list, minor=False)\n",
    "                        ax2.set_yticklabels(word_list, minor=False)\n",
    "\n",
    "                        plt.xticks(rotation=45)\n",
    "                        \n",
    "                        plt_folder_name = os.path.join(\"plt_storage\" + \"/\" + args.exp_name)\n",
    "                        if not os.path.exists(plt_folder_name):\n",
    "                            os.mkdir(plt_folder_name)          \n",
    "                        plt_folder_name = os.path.join(plt_folder_name, f\"step_{global_step}\")\n",
    "                        if not os.path.exists(plt_folder_name):\n",
    "                            os.mkdir(plt_folder_name)                        \n",
    "                        plt.savefig(plt_folder_name + \"/\" + f\"L{i}_H{head}.png\")\n",
    "                        plt.close()\n",
    "                        \n",
    "\n",
    "                    if args.log_metric:\n",
    "                        \n",
    "                        student_prob = student_prob\n",
    "                        teacher_prob = teacher_prob\n",
    "\n",
    "                        # Attention Map\n",
    "                        student_attn_map = student_prob[0][head][:seq_length,:seq_length].clone().detach()\n",
    "                        teacher_attn_map = teacher_prob[0][head][:seq_length,:seq_length].clone().detach()\n",
    "\n",
    "                        # KL Divergence\n",
    "                        kl_div = F.kl_div(student_attn_map.log(), teacher_attn_map, reduction='batchmean')\n",
    "                        kl_div_sum[i] += kl_div\n",
    "\n",
    "                        # Special Token Prob Mean\n",
    "                        st_sep_avg = student_attn_map[:,-1].mean()\n",
    "                        st_cls_avg = student_attn_map[:,0].mean()\n",
    "                        st_sep_avg_sum[i] += st_sep_avg\n",
    "                        st_cls_avg_sum[i] += st_cls_avg\n",
    "                        \n",
    "                        # Ground Truth\n",
    "                        tc_sep_avg = teacher_attn_map[:,-1].mean()\n",
    "                        tc_cls_avg = teacher_attn_map[:,0].mean()\n",
    "                        tc_sep_avg_sum[i] += tc_sep_avg\n",
    "                        tc_cls_avg_sum[i] += tc_cls_avg\n",
    "\n",
    "                        # Coverage Test\n",
    "                        coverage_head_sum = 0\n",
    "                        coverage_teacher_head_sum = 0\n",
    "                        for k in range(student_attn_map.shape[0]):\n",
    "                            st_argsort = student_attn_map[k].sort(descending=True)[1]\n",
    "                            tc_argsort = teacher_attn_map[k].sort(descending=True)[1][:args.tc_top_k] # Top-5\n",
    "                            \n",
    "                            max_idx = 0\n",
    "                            for idx in tc_argsort: # Teacher Top-5                             \n",
    "                                tmp = torch.where(st_argsort == idx)\n",
    "                                max_idx = max(tmp[0].item(), max_idx)\n",
    "                            \n",
    "                            coverage_ratio = max_idx / student_attn_map.shape[0]\n",
    "                            coverage_teacher_ratio = (args.tc_top_k - 1) / student_attn_map.shape[0]\n",
    "                            coverage_head_sum += coverage_ratio\n",
    "                            coverage_teacher_head_sum += coverage_teacher_ratio\n",
    "                        \n",
    "                        coverage_head = coverage_head_sum / student_attn_map.shape[0]\n",
    "                        coverage_teacher_head = coverage_teacher_head_sum / student_attn_map.shape[0]\n",
    "                        \n",
    "                        cover_sum[i] += coverage_head\n",
    "                        cover_teacher_sum[i] += coverage_teacher_head\n",
    "                        \n",
    "                        nb_steps += 1\n",
    "        \n",
    "        batch_num = batch_num + 1\n",
    "    \n",
    "    if args.log_metric:\n",
    "        nb_steps = nb_steps / 12\n",
    "        \n",
    "        for l in range(12):\n",
    "            run[f\"attn/L{l}_KLdiv_mean\"].log(value=kl_div_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_st_SepProb_mean\"].log(value=st_sep_avg_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_st_ClsProb_mean\"].log(value=st_cls_avg_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_tc_SepProb_mean\"].log(value=tc_sep_avg_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_tc_ClsProb_mean\"].log(value=tc_cls_avg_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_st_cover_mean\"].log(value=cover_sum[l] / nb_steps, step=global_step)\n",
    "            run[f\"attn/L{l}_tc_cover_mean\"].log(value=cover_teacher_sum[l] / nb_steps, step=global_step)\n",
    "\n",
    "    args.log_map = True                    \n",
    "\n",
    "\n",
    "def do_eval(model, task_name, eval_dataloader,\n",
    "            device, output_mode, eval_labels, num_labels, teacher_model=None):\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "\n",
    "    for batch_ in tqdm(eval_dataloader, desc=\"Inference\"):\n",
    "        batch_ = tuple(t.to(device) for t in batch_)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch_\n",
    "\n",
    "            # teacher attnmap test\n",
    "            if teacher_model is not None:\n",
    "                logits, teacher_atts, _, teacher_probs, _ = teacher_model(input_ids, segment_ids, input_mask)\n",
    "                # teacher_probs = 0\n",
    "                logits, _, _, _, _ = model(input_ids, segment_ids, input_mask, teacher_probs=teacher_probs)\n",
    "            else:\n",
    "                logits, _, _, _, _ = model(input_ids, segment_ids, input_mask)\n",
    "        \n",
    "        # create eval loss and other metric required by the task\n",
    "        if output_mode == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif output_mode == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            tmp_eval_loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(\n",
    "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "\n",
    "    preds = preds[0]\n",
    "    if output_mode == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "    elif output_mode == \"regression\":\n",
    "        preds = np.squeeze(preds)\n",
    "    result = compute_metrics(task_name, preds, eval_labels.numpy())\n",
    "    result['eval_loss'] = eval_loss\n",
    "    return result\n",
    "\n",
    "def soft_cross_entropy(predicts, targets):\n",
    "    student_likelihood = torch.nn.functional.log_softmax(predicts, dim=-1)\n",
    "    targets_prob = torch.nn.functional.softmax(targets, dim=-1)\n",
    "    return torch.sum((- targets_prob * student_likelihood), dim=-1).mean()\n",
    "\n",
    "processors = {\n",
    "    \"cola\": ColaProcessor,\n",
    "    \"mnli\": MnliProcessor,\n",
    "    \"mnli-mm\": MnliMismatchedProcessor,\n",
    "    \"mrpc\": MrpcProcessor,\n",
    "    \"sst-2\": Sst2Processor,\n",
    "    \"sts-b\": StsbProcessor,\n",
    "    \"qqp\": QqpProcessor,\n",
    "    \"qnli\": QnliProcessor,\n",
    "    \"rte\": RteProcessor   \n",
    "}\n",
    "\n",
    "output_modes = {\n",
    "        \"cola\": \"classification\",\n",
    "        \"mnli\": \"classification\",\n",
    "        \"mrpc\": \"classification\",\n",
    "        \"sst-2\": \"classification\",\n",
    "        \"sts-b\": \"regression\",\n",
    "        \"qqp\": \"classification\",\n",
    "        \"qnli\": \"classification\",\n",
    "        \"rte\": \"classification\"\n",
    "}\n",
    "\n",
    "default_params = {\n",
    "        \"cola\": {\"max_seq_length\": 64,\"batch_size\":1,\"eval_step\": 50}, # No Aug : 50 Aug : 400\n",
    "        \"mnli\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\":8000},\n",
    "        \"mrpc\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\":100},\n",
    "        \"sst-2\": {\"max_seq_length\": 64,\"batch_size\":1,\"eval_step\":100},\n",
    "        \"sts-b\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\":100},\n",
    "        \"qqp\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\":1000},\n",
    "        \"qnli\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\":1000},\n",
    "        \"rte\": {\"max_seq_length\": 128,\"batch_size\":1,\"eval_step\": 20}\n",
    "    }\n",
    "\n",
    "from bertviz import head_view, model_view\n",
    "# from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
    "from bertviz.neuron_view import show\n",
    "import bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab9bf6b",
   "metadata": {},
   "source": [
    "# GLUE Task Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75f78270",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"sts-b\"\n",
    "bert_size = \"large\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b94ac6",
   "metadata": {},
   "source": [
    "## Model Dir, Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fec849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_dir = \"models\"\n",
    "output_dir = \"output\"\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    model_dir = os.path.join(model_dir, \"BERT_large\")\n",
    "    output_dir = os.path.join(output_dir, \"BERT_large\")\n",
    "\n",
    "student_model_dir = os.path.join(model_dir,task_name)\n",
    "student_model_dir = os.path.join(output_dir, task_name, \"quant\", \"ternary_save\")\n",
    "# student_model_dir = os.path.join(output_dir, task_name, \"quant\", \"step_2_da_10\") # DA-A4W2 51.2\n",
    "teacher_model_dir = os.path.join(model_dir,task_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a99315",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fb545e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/01 06:45:11 PM Writing example 0 of 1500\n",
      "04/01 06:45:11 PM *** Example ***\n",
      "04/01 06:45:11 PM guid: dev-0\n",
      "04/01 06:45:11 PM tokens: [CLS] a man with a hard hat is dancing . [SEP] a man wearing a hard hat is dancing . [SEP]\n",
      "04/01 06:45:11 PM input_ids: 101 1037 2158 2007 1037 2524 6045 2003 5613 1012 102 1037 2158 4147 1037 2524 6045 2003 5613 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/01 06:45:11 PM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/01 06:45:11 PM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/01 06:45:11 PM label: 5.000\n",
      "04/01 06:45:11 PM label_id: 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2198397/3831030937.py:189: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Processor & Task Info\n",
    "processor = processors[task_name]()\n",
    "output_mode = output_modes[task_name]\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "\n",
    "if task_name in default_params:\n",
    "    batch_size = default_params[task_name][\"batch_size\"]\n",
    "    max_seq_length = default_params[task_name][\"max_seq_length\"]\n",
    "    eval_step = default_params[task_name][\"eval_step\"]\n",
    "    \n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(teacher_model_dir, do_lower_case=True)\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "data_dir = os.path.join(\"data\",task_name)\n",
    "processed_data_dir = os.path.join(data_dir,'preprocessed')\n",
    "\n",
    "eval_examples = processor.get_dev_examples(data_dir)\n",
    "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, output_mode)\n",
    "# dev_file = train_file = os.path.join(processed_data_dir,'dev.pkl') \n",
    "# eval_features = pickle.load(open(dev_file,'rb'))\n",
    "\n",
    "eval_data, eval_labels = get_tensor_data(\"classification\", eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=32)\n",
    "eval_data, eval_labels = get_tensor_data(output_mode, eval_features)\n",
    "\n",
    "eval_examples = processor.get_dev_examples(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b63b5",
   "metadata": {},
   "source": [
    "# Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c3a8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/01 06:44:58 PM Loading model models/BERT_large/sts-b/pytorch_model.bin\n",
      "04/01 06:44:59 PM loading model...\n",
      "04/01 06:44:59 PM done!\n",
      "04/01 06:44:59 PM loading configuration file output/BERT_large/sts-b/quant/ternary_save/config.json\n",
      "04/01 06:45:05 PM Loading model output/BERT_large/sts-b/quant/ternary_save/pytorch_model.bin\n",
      "04/01 06:45:06 PM loading model...\n",
      "04/01 06:45:06 PM done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_tc = 1\n",
    "build_st = 1\n",
    "\n",
    "if build_tc:\n",
    "    # Teacher Model Build\n",
    "    teacher_model = BertForSequenceClassification.from_pretrained(teacher_model_dir, num_labels=num_labels)\n",
    "    teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    model = teacher_model\n",
    "\n",
    "if build_st:\n",
    "    # Student Model Build\n",
    "    student_config = BertConfig.from_pretrained(student_model_dir,\n",
    "                                                    quantize_act=True,\n",
    "                                                    quantize_weight=True,\n",
    "                                                    weight_bits = 2, # Always Ternary when \"quantize_weight = True\"\n",
    "                                                    input_bits = 8,\n",
    "                                                    clip_val = 2.5,\n",
    "                                                    quantize = True,\n",
    "                                                    ffn_q_1 = True,\n",
    "                                                    ffn_q_2 = True,\n",
    "                                                    qkv_q = True,\n",
    "                                                    emb_q = True,\n",
    "                                                    cls_q = True,\n",
    "                                                    clipping = False,\n",
    "                                                    layer_num = -1,\n",
    "                                                    mean_scale = 0.7,\n",
    "                                                    quantizer = \"ternary\",\n",
    "                                                    act_quantizer = \"ternary\",\n",
    "                                                    init_scaling = 1,\n",
    "                                                    clip_ratio = 1,\n",
    "                                                    gradient_scaling = False,\n",
    "                                                    clip_method = \"minmax\",\n",
    "                                                    teacher_attnmap = False,\n",
    "                                                    parks = False,\n",
    "                                                    stop_grad = False,\n",
    "                                                    qk_FP = False,\n",
    "                                                    map=False,\n",
    "                                                    act_method = \"clipping\"\n",
    "                                                    )\n",
    "\n",
    "    student_model = QuantBertForSequenceClassification.from_pretrained(student_model_dir, config = student_config, num_labels=num_labels)\n",
    "    student_model.to(device)\n",
    "    model = student_model\n",
    "    print()\n",
    "\n",
    "    # Quantization Option ACT/WEIGHT\n",
    "    for name, module in student_model.named_modules():\n",
    "                if isinstance(module, (QuantizeLinear, QuantizeAct, ClipLinear)):    \n",
    "                    module.act_flag = True\n",
    "                    module.weight_flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2361c6",
   "metadata": {},
   "source": [
    "## Activation Quantization Clip Value Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32aa6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for name, module in student_model.named_modules():\n",
    "#             if isinstance(module, (QuantizeLinear, QuantizeAct, ClipLinear)):    \n",
    "#                 module.act_flag = False\n",
    "#                 module.weight_flag = False\n",
    "                \n",
    "# cv_initialize(student_model, eval_dataloader, torch.Tensor([0.005]), device)\n",
    "\n",
    "# # for name, module in student_model.named_modules():\n",
    "# #             if isinstance(module, (QuantizeLinear, QuantizeAct, ClipLinear)):    \n",
    "# #                 module.act_flag = True\n",
    "# #                 module.weight_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0dfd7",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c515c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Model Inferece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:27<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Result : {'pearson': 0.8887880506300738, 'spearmanr': 0.8850681732784779, 'corr': 0.8869281119542758, 'eval_loss': 0.6736781127909397}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_st = 1\n",
    "eval_tc = 0\n",
    "\n",
    "if eval_st:\n",
    "    print(\"Student Model Inferece\")\n",
    "    student_model.eval()\n",
    "    student_result = do_eval(student_model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels, teacher_model=teacher_model)\n",
    "    print(f\"Student Result : {student_result}\")\n",
    "\n",
    "if eval_tc:\n",
    "    print(\"Teacher Model Inferece\")\n",
    "    teacher_result = do_eval(teacher_model, task_name, eval_dataloader, device, output_mode, eval_labels, num_labels)\n",
    "    print(f\"Teacher Result : {teacher_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265abf87",
   "metadata": {},
   "source": [
    "## BERTViz Model View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eedf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids : tensor([[ 101, 1037, 2402, 2775, 2003, 5559, 1037, 3586, 1012,  102, 1037, 2775,\n",
      "         2003, 5559, 1037, 3586, 1012,  102]], device='cuda:0')\n",
      "tokens : ['[CLS]', 'a', 'young', 'child', 'is', 'riding', 'a', 'horse', '.', '[SEP]', 'a', 'child', 'is', 'riding', 'a', 'horse', '.', '[SEP]']\n",
      "A : a young child is riding a horse . \n",
      "B : a child is riding a horse . \n",
      "tensor([ 9, 17], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Sampling Sentence \n",
    "i = 0 \n",
    "num = 2\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    model.train()\n",
    "            \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, segment_ids, label_ids, seq_lengths = batch\n",
    "    i = i + 1\n",
    "    if i == num:\n",
    "        break\n",
    "\n",
    "seq_length = seq_lengths.item()\n",
    "input_ids_sliced = input_ids[:,:seq_length]\n",
    "input_id = []\n",
    "for i in input_ids_sliced[0]:\n",
    "    input_id.append(i.item())\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id)\n",
    "\n",
    "\n",
    "\n",
    "sample_sentence_a = str()\n",
    "sample_sentence_b = str()\n",
    "index = 0\n",
    "\n",
    "for i, word in enumerate(tokens[1:-1]):\n",
    "    if word == \"[SEP]\":\n",
    "        break\n",
    "    sample_sentence_a += word\n",
    "    sample_sentence_a += \" \"\n",
    "index = i\n",
    "\n",
    "for i, word in enumerate(tokens[index+2:-1]):\n",
    "    if word == \"[SEP]\":\n",
    "        break\n",
    "    sample_sentence_b += word\n",
    "    sample_sentence_b += \" \"\n",
    "\n",
    "sep_index = torch.where(input_ids[0] == 102)[0]\n",
    "\n",
    "if len(sample_sentence_b) > 1:\n",
    "    sample_sentence_b_start = segment_ids[0].tolist().index(1)\n",
    "\n",
    "print(f\"input_ids : {input_ids_sliced}\")\n",
    "print(f\"tokens : {tokens}\")\n",
    "print(f\"A : {sample_sentence_a}\")\n",
    "print(f\"B : {sample_sentence_b}\")\n",
    "print(sep_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780d1da2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bertviz.transformers_neuron_view import BertModel, BertTokenizer\n",
    "from bertviz.neuron_view import show\n",
    "\n",
    "bertviz_neuron_tc = 0\n",
    "bertviz_neuron_st = 0\n",
    "bertviz_model_tc = 1\n",
    "bertviz_model_st = 1\n",
    "\n",
    "# Quantization Setting\n",
    "if bertviz_neuron_st or bertviz_model_st:\n",
    "    for name, module in student_model.named_modules():\n",
    "            if isinstance(module, (QuantizeLinear, ClipLinear)):    \n",
    "                module.act_flag = False\n",
    "                module.weight_flag = False\n",
    "            if isinstance(module, QuantizeAct):    \n",
    "                module.act_flag = False\n",
    "                module.weight_flag = False\n",
    "\n",
    "if bertviz_neuron_tc or bertviz_neuron_st:\n",
    "    if bertviz_neuron_st:\n",
    "        for name, module in student_model.named_modules():\n",
    "                if isinstance(module, BertSelfAttention):    \n",
    "                    module.output_bertviz = True\n",
    "    if bertviz_neuron_tc:\n",
    "        for name, module in teacher_model.named_modules():\n",
    "                if isinstance(module, FP_BertSelfAttention):    \n",
    "                    module.output_bertviz = True\n",
    "\n",
    "    model_type = 'bert'\n",
    "    model_version = 'bert-base-uncased'\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=True)\n",
    "    if bertviz_neuron_tc:\n",
    "        if len(sample_sentence_b) > 1:\n",
    "            show(teacher_model.cpu(), model_type, tokenizer, sample_sentence_a, sample_sentence_b, display_mode=\"light\")\n",
    "        else:\n",
    "            show(teacher_model.cpu(), model_type, tokenizer, sample_sentence_a,display_mode=\"light\")\n",
    "    if bertviz_neuron_st:\n",
    "        if len(sample_sentence_b) > 1:\n",
    "            show(student_model.cpu(), model_type, tokenizer, sample_sentence_a, sample_sentence_b, display_mode=\"light\")\n",
    "        else:\n",
    "            show(student_model.cpu(), model_type, tokenizer, sample_sentence_a,display_mode=\"light\")\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    layer_num = 24\n",
    "    head_num = 16\n",
    "else:\n",
    "    layer_num = 12\n",
    "    head_num = 12\n",
    "    \n",
    "all_layers = list(range(layer_num))\n",
    "layers_to_show = all_layers[18:]\n",
    "\n",
    "if bertviz_model_tc or bertviz_model_st:\n",
    "    \n",
    "    if bertviz_model_tc:\n",
    "        print(\"teacher_map\")\n",
    "        for name, module in teacher_model.named_modules():\n",
    "                    if isinstance(module, FP_BertSelfAttention):    \n",
    "                        module.output_bertviz = False\n",
    "        teacher_model.eval()\n",
    "        teacher_model.to(device)\n",
    "        teacher_logits, teacher_atts, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids_sliced.to(device))\n",
    "        model_view(teacher_probs, tokens, include_layers=layers_to_show,  display_mode=\"light\")\n",
    "        \n",
    "    if bertviz_model_st:\n",
    "        print(\"student_map\")\n",
    "        for name, module in student_model.named_modules():\n",
    "                    if isinstance(module, BertSelfAttention):    \n",
    "                        module.output_bertviz = False\n",
    "        student_model.eval()\n",
    "        student_model.to(device)\n",
    "        student_logits, student_atts, student_reps, student_probs, student_values = student_model(input_ids_sliced.to(device), teacher_probs=teacher_probs)\n",
    "        model_view(student_probs, tokens, sample_sentence_b_start,include_layers=layers_to_show, display_mode=\"light\")# , include_layers=[0, 1])\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0039fe",
   "metadata": {},
   "source": [
    "## Forward Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64cf6575",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL DIV CHECK\n",
      "2.9676687717437744\n",
      "5.659456253051758\n",
      "3.098494052886963\n",
      "2.3057239055633545\n",
      "2.587374210357666\n",
      "1.6189770698547363\n",
      "1.2007269859313965\n",
      "1.662299633026123\n",
      "2.1250391006469727\n",
      "2.056593418121338\n",
      "3.305050849914551\n",
      "4.6170477867126465\n",
      "4.530083656311035\n",
      "4.024961948394775\n",
      "4.323973178863525\n",
      "3.5094804763793945\n",
      "3.292818784713745\n",
      "2.7897772789001465\n",
      "4.441211700439453\n",
      "8.378562927246094\n",
      "20.496295928955078\n",
      "37.17641830444336\n",
      "40.135982513427734\n",
      "76.01957702636719\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import MSELoss\n",
    "mse_func = MSELoss()\n",
    "\n",
    "if bert_size == \"large\":\n",
    "    layer_num = 24\n",
    "    head_num = 16\n",
    "else:\n",
    "    layer_num = 12\n",
    "    head_num = 12\n",
    "\n",
    "\n",
    "attention_pattern_check = 0\n",
    "cover_mean_check = 0\n",
    "kl_div_check = 1\n",
    "mse_check = 0\n",
    "attnmap_mse_check = 0\n",
    "\n",
    "exclude_sep = 0\n",
    "\n",
    "for name, module in student_model.named_modules():\n",
    "            if isinstance(module, BertSelfAttention):    \n",
    "                module.output_bertviz = False\n",
    "for name, module in teacher_model.named_modules():\n",
    "            if isinstance(module, FP_BertSelfAttention):    \n",
    "                module.output_bertviz = False\n",
    "                \n",
    "for name, module in student_model.named_modules():\n",
    "            if isinstance(module, (QuantizeLinear, ClipLinear, QuantizeAct)):    \n",
    "                module.act_flag = True\n",
    "                module.weight_flag = True\n",
    "\n",
    "seed=42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "student_model.eval()\n",
    "teacher_model.eval()\n",
    "student_model.to(device)\n",
    "teacher_model.to(device)\n",
    "teacher_logits, teacher_atts, teacher_reps, teacher_probs, teacher_values = teacher_model(input_ids_sliced.to(device))\n",
    "student_logits, student_atts, student_reps, student_probs, student_values = student_model(input_ids_sliced.to(device), teacher_probs=teacher_probs)\n",
    "\n",
    "probs = teacher_probs\n",
    "if attention_pattern_check:\n",
    "    print(\"Attention mean CHECK\")\n",
    "    for i in range(layer_num):\n",
    "        if len(sep_index) == 2:\n",
    "            print((probs[i][0,:,:,sep_index[0]].mean() + probs[i][0,:,:,sep_index[1]].mean()).item())\n",
    "        else:\n",
    "            print(probs[i][0,:,:,sep_index[0]].mean().item())\n",
    "    \n",
    "if cover_mean_check:\n",
    "    print(\"COVER MEAN CHECK\")\n",
    "    top_k = 5\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        teacher = teacher_probs[i][0]\n",
    "        student = student_probs[i][0]\n",
    "\n",
    "        head_sum = 0\n",
    "        for h in range(head_num):\n",
    "            coverage_head_sum = 0\n",
    "            for row in range(seq_length-1):\n",
    "                if exclude_sep:\n",
    "                    tc_argsort = teacher[h][:seq_length-1,:seq_length-1].sort(descending=True)[1][row][:top_k] # top-k\n",
    "                    st_argsort = student[h][:seq_length-1,:seq_length-1].sort(descending=True)[1][row]\n",
    "                tc_argsort = teacher[h].sort(descending=True)[1][row][:top_k] # top-k\n",
    "                st_argsort = student[h].sort(descending=True)[1][row]\n",
    "\n",
    "                max_idx = 0\n",
    "                for idx in tc_argsort:\n",
    "                    tmp = torch.where(st_argsort == idx)\n",
    "                    max_idx = max(tmp[0].item(), max_idx)\n",
    "\n",
    "                coverage_ratio = max_idx / student.shape[1]\n",
    "                coverage_head_sum += coverage_ratio\n",
    "\n",
    "                # print(f\"H{h} : {coverage_head_sum/seq_length}\")\n",
    "\n",
    "            head_sum += coverage_head_sum / seq_length\n",
    "        print(head_sum / head_num)\n",
    "\n",
    "if kl_div_check:\n",
    "    print(\"KL DIV CHECK\")\n",
    "    for i in range(layer_num):\n",
    "        if exclude_sep:\n",
    "            if len(sep_index) == 2:\n",
    "                teacher_atts[i][:,:,:,sep_index[0]] = -100000; teacher_atts[i][:,:,:,sep_index[1]] = -100000\n",
    "                student_atts[i][:,:,:,sep_index[0]] = -100000; student_atts[i][:,:,:,sep_index[1]] = -100000\n",
    "            else:\n",
    "                teacher_atts[i][:,:,:,sep_index[0]] = -100000\n",
    "                student_atts[i][:,:,:,sep_index[0]] = -100000\n",
    "                \n",
    "            teacher = torch.nn.Softmax(dim=-1)(teacher_atts[i])\n",
    "            student = torch.nn.Softmax(dim=-1)(student_atts[i])\n",
    "            \n",
    "            student = torch.clamp_min(student, 1e-8)\n",
    "            teacher = torch.clamp_min(teacher, 1e-8)\n",
    "        else:    \n",
    "            teacher = teacher_probs[i]\n",
    "            student = student_probs[i]\n",
    "        \n",
    "        neg_cross_entropy = teacher * torch.log(student) \n",
    "        neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "        neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "        # p(t) log p(t) = negative entropy\n",
    "        neg_entropy = teacher * torch.log(teacher) \n",
    "        neg_entropy = torch.sum(neg_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "        neg_entropy = torch.sum(neg_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "        kld_loss = neg_entropy - neg_cross_entropy\n",
    "\n",
    "        kld_loss_sum = torch.sum(kld_loss)\n",
    "        print(kld_loss_sum.item())\n",
    "\n",
    "if mse_check:\n",
    "    for i in range(layer_num):\n",
    "        print(mse_func(teacher_atts[i], student_atts[i]).item())\n",
    "        \n",
    "if attnmap_mse_check:\n",
    "    for i in range(layer_num):\n",
    "        if exclude_sep:\n",
    "            if len(sep_index) == 2:\n",
    "                teacher_atts[i][:,:,:,sep_index[0]] = -100000; teacher_atts[i][:,:,:,sep_index[1]] = -100000\n",
    "                student_atts[i][:,:,:,sep_index[0]] = -100000; student_atts[i][:,:,:,sep_index[1]] = -100000\n",
    "            else:\n",
    "                teacher_atts[i][:,:,:,sep_index[0]] = -100000\n",
    "                student_atts[i][:,:,:,sep_index[0]] = -100000\n",
    "                \n",
    "            teacher = torch.nn.Softmax(dim=-1)(teacher_atts[i])\n",
    "            student = torch.nn.Softmax(dim=-1)(student_atts[i])\n",
    "            print(mse_func(teacher, student).item())\n",
    "        else:    \n",
    "            print(mse_func(teacher_probs[i], student_probs[i]).item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1cfe75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.155358076095581\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 9\n",
    "teacher = teacher_probs[1][:,i,:,:]\n",
    "student = student_probs[1][:,i,:,:]\n",
    "\n",
    "\n",
    "\n",
    "neg_cross_entropy = teacher * torch.log(student) \n",
    "neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "# p(t) log p(t) = negative entropy\n",
    "neg_entropy = teacher * torch.log(teacher) \n",
    "neg_entropy = torch.sum(neg_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "neg_entropy = torch.sum(neg_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "kld_loss = neg_entropy - neg_cross_entropy\n",
    "\n",
    "kld_loss_sum = torch.sum(kld_loss)\n",
    "print(kld_loss_sum.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81a859c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4594290256500244\n",
      "0.5127482414245605\n",
      "0.5085060596466064\n",
      "0.44210290908813477\n",
      "0.3044252395629883\n",
      "0.4317352771759033\n",
      "0.43944454193115234\n",
      "0.34624576568603516\n",
      "0.45526742935180664\n",
      "0.4619622230529785\n",
      "0.2999594211578369\n",
      "0.5414872169494629\n",
      "0.4033381938934326\n",
      "0.3882777690887451\n",
      "0.3862929344177246\n",
      "0.29909467697143555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "head = 7\n",
    "for head in range(16):\n",
    "    teacher = teacher_probs[23][:,head,:,:]\n",
    "    student = student_probs[23][:,head,:,:]\n",
    "    neg_cross_entropy = teacher * torch.log(student) \n",
    "    neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "    neg_cross_entropy = torch.sum(neg_cross_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "    # p(t) log p(t) = negative entropy\n",
    "    neg_entropy = teacher * torch.log(teacher) \n",
    "    neg_entropy = torch.sum(neg_entropy, dim=-1)  # (b, h, s, s) -> (b, h, s)\n",
    "    neg_entropy = torch.sum(neg_entropy, dim=-1) / seq_lengths.view(-1, 1)  # (b, h, s) -> (b, h)\n",
    "\n",
    "    kld_loss = neg_entropy - neg_cross_entropy\n",
    "\n",
    "    kld_loss_sum = torch.sum(kld_loss)\n",
    "    print(kld_loss_sum.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dab8d045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.1772e-02, 1.2781e-02, 4.9408e-03,  ..., 2.0158e-02,\n",
       "          6.9626e-02, 1.4999e-02],\n",
       "         [1.0919e-03, 2.1085e-03, 1.0577e-03,  ..., 1.6647e-04,\n",
       "          4.3606e-04, 1.8829e-01],\n",
       "         [2.0435e-04, 2.2089e-04, 1.0611e-04,  ..., 4.0684e-05,\n",
       "          4.6589e-05, 1.9174e-01],\n",
       "         ...,\n",
       "         [1.2242e-03, 9.6587e-05, 5.1341e-05,  ..., 2.4791e-03,\n",
       "          8.4426e-04, 2.3197e-01],\n",
       "         [3.1989e-05, 1.6445e-05, 4.2517e-06,  ..., 5.4571e-05,\n",
       "          1.5931e-05, 1.9737e-01],\n",
       "         [2.7168e-02, 1.6892e-02, 1.5799e-02,  ..., 1.5508e-02,\n",
       "          2.3137e-02, 4.5687e-02]]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_probs[23][:,7,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "857ecb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8724, 0.4891, 0.6094, 0.6159, 0.4543, 0.4242, 0.5964, 0.1814, 0.7470,\n",
       "         0.3960, 0.4766, 0.3705, 0.6179, 0.2615, 0.6612, 0.4897, 0.6067, 0.3899,\n",
       "         0.4389, 0.7189, 0.3123, 0.2026, 0.3890, 0.2045, 0.5183, 0.4821, 0.4648,\n",
       "         0.2569, 0.2587, 0.4544, 0.2224, 0.6254, 0.7420, 0.1829, 0.5220, 0.2288,\n",
       "         0.6594, 0.6613, 0.4734, 0.7735, 0.7583, 0.2122, 0.6728, 0.2626, 0.7567,\n",
       "         0.2797, 0.7548, 0.4164, 0.7275]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_probs[1][:,9,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2440e7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
